## **机器学习**
***
### **监督学习**
* 学习x到y或输入到输出映射的算法
* 例如：输入为一个email，判断其是否为垃圾email；输入一串英文，翻译出一串汉字；从你的个人信息判断你是否会点击广告/感兴趣话题......，这些应用十分广泛，包括但不限于，翻译，邮件，无人驾驶，广告投放......
* 输入x与标签y来训练模型
* 回归算法：例如线性回归预测数字，从无限多的可能的输出数字中预测数字
* 分类算法：对一个类别做出预测，包括小概率出现的可能，不一定为数字，可以为任何东西，例如预测一个图片所显示的是猫还是狗，或不同大小的肿瘤是良性还是恶性。可以设置多个输入。而学习算法要将这些判断的边界线拟合到数据上：
* >例如在肿瘤判断中，使用年龄与肿瘤大小判断良性与恶性，算法则需要在良性与恶性之间的边界线进行拟合，使其与数据尽量符合

### **无监督学习**
* 给定的数据与任何输出标签y无关，即不尝试**监督**算法，无需去预测某件事情的发生，只需对于给定数据进行一些观察，例如对数据集的结构、模式。
* 无监督学习会将数据分成两个或更多的组/集群，即聚类算法 ，将未被标记的数据放入不同集群之中。例如搜索引擎，每天读取大量数据，并将相似数据组成一个集群，形成一个相关联的文章群，而且并非人工选择关键词，而是算法自己寻找。
* 与监督学习的区别：没有人为指出某些特征是存在的/与输出相关联的，交由算法自己去整合特征

### **训练集、验证集、测试集**

* 训练集（Training Set）

>- **定义**：用于训练模型的数据集。模型通过训练集学习数据的特征和模式
>- **作用**：模型通过训练集调整参数，使其能够拟合数据

* 验证集（Validation Set）

>- **定义**：用于调整模型超参数和选择模型的数据集。验证集帮助评估模型在未见过的数据上的表现
>- **作用**：
  - 选择最佳的超参数（如学习率、正则化参数等）
  - 防止过拟合，确保模型具有良好的泛化能力

* 测试集（Test Set）

>- **定义**：用于最终评估模型性能的数据集。测试集是模型从未见过的数据，用于模拟真实世界的表现
>- **作用**：评估模型的最终性能，确保模型在实际应用中的可靠性

**数据划分比例**

- 常见的划分比例是：
  - 训练集：70%
  - 验证集：15%
  - 测试集：15%
- 如果数据量较大，可以适当减少验证集和测试集的比例

### 过拟合与欠拟合
**过拟合**

*  模型在训练集上表现很好，但在验证集或测试集上表现较差。通常是因为模型过于复杂，记住了训练数据的噪声和细节。即在训练集中误差很低、验证集中误差高
*  解决办法：增加数据量、减少模型复杂度、使用正则化、使用早停

**欠拟合**
* 模型在训练集和验证集上都表现不佳。通常是因为模型过于简单，无法捕捉数据的复杂模式
* 解决办法：增加模型复杂度、增加特征、减少正则化

### 损失函数
* 用于衡量模型预测值与实际值之间的差异，模型目的是为了最小化损失函数
* 常用损失函数：
* **均方误差（MSE）**：用于回归问题，计算预测值与真实值之间的平方差

* **交叉熵损失（Cross-Entropy Loss）**：用于分类问题，衡量预测概率分布与真实分布之间的差异

* **绝对值误差（MAE）**：用于回归问题，计算预测值与真实值之间的绝对差

### 模型评价指标
* **准确率**：正确预测的样本占总样本的比例
* **精准率**：预测为正类的样本中，实际为正类的比例
* **召回率**：实际为正类的样本中，预测为正类的比例
* **F1分数**：精确率和召回率的调和平均数，用于平衡两者

### 常见的数据清洗
* **处理缺失值**：
1. 删除缺失值
2. 填充缺失值：使用均值、中位数、众数或插值法填充
* **处理异常值**
1. 通过统计方法检测并处理
* **数据标准/归一化**
1. 标准化：将数据转化为均值为0，标准差为1的分布
2. 归一化：将数据缩放到`[0,1]`或`[-1,1]`之间
* **处理类别数据**
1. 标签编码：将类别变量转化为一个标签
2. 独热编码：将类别变量转化为二进制向量

### 特征工程

- **特征选择**：
  - 从原始特征中选择最重要的特征，减少模型复杂度，提高泛化能力
  - 方法：过滤法（如相关系数）、包装法（如递归特征消除）、嵌入法（如L1正则化）
- **特征提取**：
  - 通过变换或组合原始特征生成新的特征
  - 方法：主成分分析（PCA）、线性判别分析（LDA）、特征组合（如多项式特征）
- **特征缩放**：
  - 将特征缩放到相同的尺度，常见的缩放方法有标准化和归一化
